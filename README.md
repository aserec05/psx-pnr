# PSX PNR â€” Pakistan Stock Exchange Personalized News Recommender

A personalized news recommendation system for PSX investors using NLP embeddings and user profiling.

> UniversitÃ© Claude Bernard Lyon 1 â€” Adam Muhammad Safi Ullah & Ceresa Thomas

---

## Project Status

This project is currently in active development. Here is where we stand:

| Step | Status |
|---|---|
| Data Collection | âœ… Done |
| EDA (all 3 datasets) | âœ… Done |
| Preprocessing | âœ… Done |
| Embeddings (Word2Vec + SBERT) | âœ… Done |
| Embedding Comparison | âœ… Done |
| Recommender Engine | ðŸ”„ In progress |
| User Profiling | ðŸ”„ In progress |
| Streamlit Interface | â³ Planned |
| Evaluation (Precision@K, NDCG) | â³ Planned |

---

## Project Structure

```
psx-pnr/
â”œâ”€â”€ notebooks/                        # Start here â€” run these in order
â”‚   â”œâ”€â”€ 01_eda_cnhpsx.ipynb           # EDA on CNH-PSX Mendeley dataset
â”‚   â”œâ”€â”€ 02_eda_pakistan_news.ipynb    # EDA on Pakistan News Headlines
â”‚   â”œâ”€â”€ 03_eda_psx_stocks.ipynb       # EDA on PSX Stock Market Data
â”‚   â”œâ”€â”€ 04_preprocessing.ipynb        # Preprocessing pipeline for all datasets
â”‚   â””â”€â”€ 05_embeddings.ipynb           # Word2Vec + SBERT training and comparison
â”œâ”€â”€ src/                              # Clean reusable modules (used by notebooks)
â”‚   â”œâ”€â”€ text_cleaner.py               # Generic text cleaning functions
â”‚   â”œâ”€â”€ dataset_preprocessor.py       # Dataset-specific preprocessing
â”‚   â”œâ”€â”€ embeddings.py                 # Word2Vec and SBERT embedding generation
â”‚   â””â”€â”€ recommender.py                # (in progress) Top-K recommendation engine
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                          # Original CSV files (not committed to git)
â”‚   â””â”€â”€ processed/                    # Cleaned CSVs and saved embeddings (.npy, .model)
â”œâ”€â”€ doc/                              # PDF exports of all notebooks + slides
â”œâ”€â”€ app.py                            # (planned) Streamlit interface
â””â”€â”€ requirements.txt
```

---

## Datasets

| Dataset | Source | Usage | Size after cleaning |
|---|---|---|---|
| CNH-PSX Categorized Financial News | [Mendeley](https://data.mendeley.com/datasets/mc4s7zvx9c/1) | Main news corpus for recommendation | 8 858 headlines |
| Pakistan News Headlines | [Kaggle](https://www.kaggle.com/datasets/zusmani/pakistan-news-headlines) | Word2Vec training corpus | 25 912 articles |
| PSX Stock Market Data 2017â€“2025 | [Kaggle](https://www.kaggle.com/datasets/fayaznoor10/pakistan-stock-market-data-20172025) | Optional recency weighting | 813 588 rows, 891 tickers |

---

## Getting Started

### 1. Clone the repo and go into the project folder

```bash
cd psx-pnr
```

### 2. Create a virtual environment

```bash
python3 -m venv venv
source venv/bin/activate        # Linux / WSL
venv\Scripts\activate           # Windows PowerShell
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

The main libraries used are:

- **pandas** â€” data manipulation
- **numpy** â€” numerical operations
- **scikit-learn** â€” cosine similarity, evaluation metrics
- **nltk** â€” stopword removal, lemmatization
- **gensim** â€” Word2Vec training
- **sentence-transformers** â€” SBERT pretrained models
- **streamlit** â€” web interface (planned)
- **jupyter** â€” notebooks
- **matplotlib / seaborn** â€” visualizations
- **tqdm** â€” progress bars

### 4. Download the datasets (if necessary)

Download the raw CSV files from the links above and place them in `data/raw/`:

```
data/raw/
â”œâ”€â”€ CNH-PSX_Ver1.csv
â”œâ”€â”€ CNH-PSX_Ver2.csv
â”œâ”€â”€ pakistan_news.csv
â””â”€â”€ psx_stocks.csv
```

### 5. Run the notebooks in order

```bash
jupyter notebook --no-browser
```

> On WSL, copy the `http://127.0.0.1:8888/?token=...` link into your Windows browser.

We recommend running the notebooks rather than the `src/` scripts directly â€” they include visualizations, outputs, and step-by-step explanations. The `src/` modules are the clean reusable code called by the notebooks.

---

## Key Findings So Far

### Preprocessing
- CNH-PSX headlines contained `['...']` artifacts that were cleaned
- 3 354 duplicate headlines removed from CNH-PSX (~27%)
- Pakistan News: 24 574 duplicates removed, date column partially unparseable â€” used text only for Word2Vec
- PSX Stocks: filtered rows with zero volume, 2 767 NaN filled in `CHANGE (%)`

### Embeddings

We compared 4 models on 3 tests (CNH-PSX headlines, Pakistan News sections, PSX ticker mentions):

| Model | CNH-PSX Î” | Stocks Î” | Notes |
|---|---|---|---|
| Word2Vec (clean) | **0.22** | â€” | Best for PSX-specific news |
| SBERT-MiniLM (raw) | 0.07 | 0.03 | Good balance, fast |
| SBERT-MPNet (raw) | -0.005 | **0.11** | Best for ticker matching |
| SBERT-Multilingual (raw) | -0.04 | 0.06 | Underperforms on this corpus |

**Key insight**: SBERT performs better on raw headlines than preprocessed ones â€” aggressive cleaning (stopword removal, lemmatization) removes context that SBERT needs. Word2Vec benefits from cleaning since it works word by word.

**Chosen strategy**: Word2Vec for the main recommendation engine, SBERT-MPNet for ticker-to-news linking.

---

## Documentation

All notebook outputs (EDA results, preprocessing summaries, embedding comparisons) are exported as PDFs in the `doc/` folder, along with the project slides.

---

## Pipeline Overview

```
Raw Data (CSV)
     â†“
Preprocessing (text_cleaner.py + dataset_preprocessor.py)
     â†“
Embeddings (embeddings.py) â†’ .npy files saved in data/processed/
     â†“
User Profile (interests + watchlist)
     â†“
Cosine Similarity + Ranking
     â†“
Top-K News Recommendations
```

---

## Known Limitations

- CNH-PSX corpus only covers 2006â€“2017 â€” no recent news
- Headlines are short (~7 words on average) which limits embedding quality
- No full article text available â€” headlines only
- Synthetic user profiles used (no real user interaction data)